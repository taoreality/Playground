{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1CMNg96D0JV7A-QqOP28ufHBxvq6KuPxc",
      "authorship_tag": "ABX9TyPjk4/+3pkd04KqzDr/f9pF"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Define image data generator\n",
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/Signatures/iam-handwriting-database/',\n",
        "    target_size=(28, 28),\n",
        "    batch_size=32,\n",
        "    class_mode='input',  # Use input as the class mode for autoencoder\n",
        "    color_mode='grayscale',  # Assuming images are grayscale\n",
        "    subset='training'  # Training split\n",
        ")\n",
        "\n",
        "# Define the model architecture\n",
        "input_layer = Input(shape=(28, 28, 1))\n",
        "x = Flatten()(input_layer)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "output_layer = Dense(784, activation='sigmoid')(x)\n",
        "\n",
        "model = Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "# Compile and train the model\n",
        "model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.fit(train_generator, epochs=10, validation_data=validation_generator)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "Xoj6ZlImJ7g1",
        "outputId": "7fa27fe5-5c7a-49a0-c318-77fc55c30f1a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 489 images belonging to 247 classes.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'validation_generator' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-54e10d51fae4>\u001b[0m in \u001b[0;36m<cell line: 28>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# Compile and train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'validation_generator' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Define image data generator\n",
        "datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)  # Splitting into training and validation sets\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/Signatures/iam-handwriting-database/',\n",
        "    target_size=(28, 28),\n",
        "    batch_size=32,\n",
        "    class_mode='binary',  # Assuming binary classification (genuine vs. forged)\n",
        "    color_mode='grayscale',  # Assuming images are grayscale\n",
        "    subset='training'  # Training split\n",
        ")\n",
        "\n",
        "validation_generator = datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/Signatures/iam-handwriting-database/',\n",
        "    target_size=(28, 28),\n",
        "    batch_size=32,\n",
        "    class_mode='binary',\n",
        "    color_mode='grayscale',\n",
        "    subset='validation'  # Validation split\n",
        ")\n",
        "\n",
        "# Define the model architecture\n",
        "input_layer = Input(shape=(28, 28, 1))\n",
        "x = Flatten()(input_layer)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "output_layer = Dense(1, activation='sigmoid')(x)  # Binary classification output\n",
        "\n",
        "model = Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "# Compile and train the model\n",
        "model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.fit(train_generator, epochs=10, validation_data=validation_generator)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lM9cIw2SM3Bv",
        "outputId": "7aa8e842-e8a1-4ee9-b058-2271b88f3a87"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 452 images belonging to 247 classes.\n",
            "Found 37 images belonging to 247 classes.\n",
            "Epoch 1/10\n",
            "15/15 [==============================] - 206s 14s/step - loss: -2781.6709 - accuracy: 0.0044 - val_loss: -6580.9004 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "15/15 [==============================] - 40s 3s/step - loss: -10067.7188 - accuracy: 0.0044 - val_loss: -15068.0488 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "15/15 [==============================] - 36s 2s/step - loss: -19857.0137 - accuracy: 0.0044 - val_loss: -26183.8672 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "15/15 [==============================] - 40s 3s/step - loss: -32475.4648 - accuracy: 0.0044 - val_loss: -40082.7891 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/10\n",
            "15/15 [==============================] - 36s 2s/step - loss: -47332.9336 - accuracy: 0.0044 - val_loss: -57474.0938 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/10\n",
            "15/15 [==============================] - 42s 3s/step - loss: -66781.4375 - accuracy: 0.0044 - val_loss: -78585.6094 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/10\n",
            "15/15 [==============================] - 34s 2s/step - loss: -89478.9766 - accuracy: 0.0044 - val_loss: -103393.9766 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/10\n",
            "15/15 [==============================] - 35s 2s/step - loss: -115942.4844 - accuracy: 0.0044 - val_loss: -131740.1719 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/10\n",
            "15/15 [==============================] - 34s 2s/step - loss: -146436.9688 - accuracy: 0.0044 - val_loss: -163939.1719 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/10\n",
            "15/15 [==============================] - 37s 2s/step - loss: -179399.5781 - accuracy: 0.0044 - val_loss: -199716.9531 - val_accuracy: 0.0000e+00\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7a3cf6c075b0>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    }
  ]
}